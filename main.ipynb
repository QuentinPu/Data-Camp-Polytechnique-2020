{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\"><a href=\"http://www.datascience-paris-saclay.fr\">\n",
    "<img border=\"0\" src=\"http://project.inria.fr/saclaycds/files/2017/02/logoUPSayPlusCDS_990.png\" width=\"90%\"> </td>\n",
    "     <td style=\"background-color:transparent;\"><a href=\"https://www.sidetrade.com/\">\n",
    "<img border=\"0\" src=\"https://www.sidetrade.com/wp-content/uploads/22050384_10213210110060640_1095182809_o-300x117.png\" width=\"60%\"> </td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>FAN revenue prediction challenge</h1></center>\n",
    "<br/>\n",
    "<center>Lucy Liu (CDS), Maria Teleczuk (CDS), Cl√©ment Chastagnol (Sidetrade),<br /> Gael Varoquaux (Inria, Parietal), Alex Gramfort (Inria, Parietal), Guillaume Lemaitre (Scikit-learn @ Inria Foundation)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting revenue using French Attribution Notices: [RAMP studio challenge](https://ramp.studio/problems/fan_revenue_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [Introduction](#Introduction)\n",
    "1. [Data](#Data)\n",
    "3. [Score metric](#Score-metric)\n",
    "4. [Data exploration](#Data-exploration)\n",
    "5. [Predictions](#Predictions)\n",
    "6. [Record linkage](#Record-linkage)\n",
    "7. [Submission structure](#Submission-structure)\n",
    "8. [Local testing](#Local-testing-(before-submission))\n",
    "9. [Submitting to RAMP studio](#Submitting-to-[ramp.studio](http://ramp.studio))\n",
    "10. [More information](#More-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The objective of this challenge is to work with 'dirty data'. Most real data is dirty and the availability of high-quality, open-source ML and data analysis frameworks (such as [scikit-learn](https://scikit-learn.org/),\n",
    "[pandas](https://pandas.pydata.org/)...) means that the next frontier for tooling and automation lies in preprocessing. This challenge aims to investigate methodologies to perform statistical analysis directly on the original dirty data.\n",
    "\n",
    "There are two datasets in this challenge:\n",
    "\n",
    "* `company_revenue_TRAIN.csv` - company revenue declarations.\n",
    "* `award_notices_RAMP.csv` -  French Attribution Notices.\n",
    "\n",
    "# Aim\n",
    "\n",
    "The predictive aim of this challenge is to use `company_revenue_TRAIN.csv` and `award_notices_RAMP.csv` to predict the Revenue for each entry in the 'company financial data' dataset. It is advised that you use both datasets, as it improves the prediction (see [Score comparison](#Score-comparison)), but using only the `company_revenue_TRAIN.csv` dataset is also allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Company financial data\n",
    "\n",
    "This dataset was built from an extract of the [National Institute of Statistics and Economic Studies (INSEE)](https://www.insee.fr/en/accueil) reference database of company revenue declarations from 2013 to 2018. Each row represents the declaration of one company for one year and the following information is provided in the columns:\n",
    "\n",
    "* `Legal_ID` - the reconcilled legal ID of the company\n",
    "* `Name` - the name of the company\n",
    "* `Activity_code (APE)` - 'Activite Principale de l'Entreprise', the main activity of the company - more information in [English](https://www.startbusinessinfrance.com/code-ape) or in [French](https://www.service-public.fr/professionnels-entreprises/vosdroits/F33050)\n",
    "* `Address` \n",
    "* `Zipcode`\n",
    "* `City`\n",
    "* `Revenue` - in Euros\n",
    "* `Headcount`\n",
    "* `Fiscal_year_end_date`\n",
    "* `Fiscal_year_duration_in_months`\n",
    "* `Year`\n",
    "\n",
    "There are a few things to note:\n",
    "\n",
    "* there are revenue declarations for the same company but different years\n",
    "* there is a large reduction in entries for the years 2017 and 2018 due to the Loi Macron law in 2017\n",
    "* the 'same company' can have several different entities, resulting in entries where the `Legal_ID` is different but the `Name`, `Address`, `City` and `Zipcode` are all the same.\n",
    "* `Revenue` can be negative. A negative revenue may be due to cancelled orders from the previous fiscal year that was recorded in the current fiscal year.\n",
    "\n",
    "\n",
    "## Award notices\n",
    "\n",
    "Every French public organisation has to issue a call for tenders when buying supplies or services (above a minimum threshold). These are called public procurement contracts. Companies then compete anonymously on these contracts and when a bid is awarded, a notice has to be legally published by the public organization on the [BOAMP](https://www.boamp.fr/) (historical data is hosted by the [DILA](https://www.dila.premier-ministre.gouv.fr/)). These are called French Attribution Notices (FAN). About 25% of awards are actually electronically published.\n",
    "\n",
    "Each contract can be divided into a maximum of 5 lots and the same company can win >1 lot of a contract. The award notices dataset comprises award notices from 2017 and 2018. Each row refers to one lot and there can be up to 5 lots referring to the same contract. The following information is provided for each lot:\n",
    "\n",
    "* `ID_call` - ID of the award notice\n",
    "* `Publication_date` of the award notice\n",
    "* `End_of_call_date` of the award notice\n",
    "* `Departments_of_publication` - the department code(s) of the award notice\n",
    "* `Department_of_provision` - the department code(s) where the contract works/goods/services were provided \n",
    "* `Call_summary` - summary of the award notice\n",
    "* `Call_title` - title of the award notice\n",
    "* `Complete_call_description` - description of the award notice\n",
    "* `Total_amount` - total amount of the contract, from all lots, in euros\n",
    "* `CPV_classes` - Common Procurement Vocabulary (CPV), a classification system for public procurement used to describe the subject of procurement contracts (more information can be found [here](https://simap.ted.europa.eu/cpv))\n",
    "Columns providing details about the company issuing the contract:\n",
    "* `Buyer_name` \n",
    "* `Buyer_address`\n",
    "* `Buyer_zipcode`\n",
    "* `Buyer_city`\n",
    "* `Buyer_email`\n",
    "* `Buyer_URL`\n",
    "\n",
    "* `Contract_awarded` - whether or not the contact was awarded\n",
    "\n",
    "Columns providing details about the winner of each lot:\n",
    "\n",
    "* `ID` - unique lot ID \n",
    "* `awarded` - whether or not the contact was awarded\n",
    "* `description` - description of the lot\n",
    "* `incumbent_name` - name of the lot winnter\n",
    "* `incumbent_address` - address of the lot winner\n",
    "* `incumbent_zipcode` - zipcode of the lot winner\n",
    "* `incumbent_city` - city of the lot winner\n",
    "* `incumbent_country` - country of the lot winner\n",
    "* `number_of_received_bids` - number of bids this lot received\n",
    "* `amount` - amount of the lot in euros\n",
    "\n",
    "**Important notes**\n",
    "\n",
    "Both data sets are very dirty. There is a lot of missing data and the column descriptions provided above are a guide only. Further, the award notices dataset is much smaller than the company revenue declarations dataset. Therefore, it is expected that many companies in the company revenue declarations dataset are not present in the award notices dataset.\n",
    "\n",
    "## Training and test\n",
    "\n",
    "The company revenue training dataset has been split into 'training' and 'test' subsets. The shapes are:\n",
    "\n",
    "* training: (1 495 948, 11)\n",
    "* test: (520 966, 11)\n",
    "\n",
    "Your model will be tested on a completely separate company revenue dataset stored on the RAMP server. This dataset has a shape of (702 181, 11). This test dataset will also be dirty but we can guarantee that the following columns will (only) be of numerical data type:\n",
    "\n",
    "* `Legal_ID`\n",
    "* `Headcount`\n",
    "* `Fiscal_year_duration_in_months`\n",
    "* `Year`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score metric\n",
    "\n",
    "A unique score is used:\n",
    "\n",
    "$$score =  |max(5,log_{10}(max(1,y\\_true))) - max(5,log_{10}(max(1,y\\_pred)))| $$\n",
    "\n",
    "Score interpretation:\n",
    "\n",
    "* A lower score is better\n",
    "* Any `y_true` or `y_pred` value less than 1 is 'taken' as 1\n",
    "* If both the `y_true` and `y_pred` are less than 100 000, the score would be 0.\n",
    "* The score is the same regardless of the order of `y_true` and `y_pred` in the equation.\n",
    "* If the difference in raw `y_true` and `y_pred` values is the same, the score is greater for smaller magnitudes of `y_true` and `y_pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import recordlinkage.preprocessing\n",
    "from itertools import chain\n",
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "\n",
    "X_df, y_array = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Legal_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Activity_code (APE)</th>\n",
       "      <th>Address</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>City</th>\n",
       "      <th>Headcount</th>\n",
       "      <th>Fiscal_year_end_date</th>\n",
       "      <th>Fiscal_year_duration_in_months</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>582296</td>\n",
       "      <td>COMICOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOULOUPARIS BP 15 BOULOUPARIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>582981</td>\n",
       "      <td>CIANFARANI JEAN-MICHEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33 AVENUE H. LAFLEUR - VICTOIRE - B.P. 4031 NO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>588541</td>\n",
       "      <td>OK POULET 5EME SARL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 RUE PAUL BERT</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>NOUMEA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Legal_ID                    Name Activity_code (APE)  \\\n",
       "0    582296                 COMICOB                 NaN   \n",
       "1    582981  CIANFARANI JEAN-MICHEL                 NaN   \n",
       "2    588541     OK POULET 5EME SARL                 NaN   \n",
       "\n",
       "                                             Address  Zipcode    City  \\\n",
       "0                      BOULOUPARIS BP 15 BOULOUPARIS      NaN     NaN   \n",
       "1  33 AVENUE H. LAFLEUR - VICTOIRE - B.P. 4031 NO...      NaN     NaN   \n",
       "2                                   23 RUE PAUL BERT  98800.0  NOUMEA   \n",
       "\n",
       "   Headcount Fiscal_year_end_date  Fiscal_year_duration_in_months    Year  \n",
       "0        NaN           2016-12-31                            12.0  2016.0  \n",
       "1        NaN           2016-12-31                            12.0  2016.0  \n",
       "2        1.0           2016-12-31                            12.0  2016.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['Fiscal_year_end_date'] = pd.to_datetime(X_df['Fiscal_year_end_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495948, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                          0.000000\n",
       "Name                              0.000002\n",
       "Activity_code (APE)               0.012293\n",
       "Address                           0.175296\n",
       "Zipcode                           0.167944\n",
       "City                              0.000313\n",
       "Headcount                         0.637439\n",
       "Fiscal_year_end_date              0.000000\n",
       "Fiscal_year_duration_in_months    0.000000\n",
       "Year                              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NaN values\n",
    "X_df.isna().sum() / X_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                          563929\n",
       "Name                              528646\n",
       "Activity_code (APE)                  964\n",
       "Address                           276152\n",
       "Zipcode                             7471\n",
       "City                               29498\n",
       "Headcount                           2224\n",
       "Fiscal_year_end_date                 300\n",
       "Fiscal_year_duration_in_months         1\n",
       "Year                                   6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values\n",
    "X_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                                   int64\n",
       "Name                                      object\n",
       "Activity_code (APE)                       object\n",
       "Address                                   object\n",
       "Zipcode                                  float64\n",
       "City                                      object\n",
       "Headcount                                float64\n",
       "Fiscal_year_end_date              datetime64[ns]\n",
       "Fiscal_year_duration_in_months           float64\n",
       "Year                                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Legal_ID</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Headcount</th>\n",
       "      <th>Fiscal_year_duration_in_months</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.495948e+06</td>\n",
       "      <td>1.244713e+06</td>\n",
       "      <td>5.423720e+05</td>\n",
       "      <td>1495948.0</td>\n",
       "      <td>1.495948e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5.060829e+08</td>\n",
       "      <td>5.464419e+04</td>\n",
       "      <td>8.736985e+01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.014475e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.417373e+08</td>\n",
       "      <td>2.755171e+04</td>\n",
       "      <td>9.002249e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.246598e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.822960e+05</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-3.900000e+01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.149439e+08</td>\n",
       "      <td>3.185000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.895445e+08</td>\n",
       "      <td>6.053000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>5.293306e+08</td>\n",
       "      <td>7.511600e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.999905e+08</td>\n",
       "      <td>9.889500e+04</td>\n",
       "      <td>5.450000e+06</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.018000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Legal_ID       Zipcode     Headcount  \\\n",
       "count  1.495948e+06  1.244713e+06  5.423720e+05   \n",
       "mean   5.060829e+08  5.464419e+04  8.736985e+01   \n",
       "std    1.417373e+08  2.755171e+04  9.002249e+03   \n",
       "min    5.822960e+05  6.000000e+00 -3.900000e+01   \n",
       "25%    4.149439e+08  3.185000e+04  1.000000e+00   \n",
       "50%    4.895445e+08  6.053000e+04  3.000000e+00   \n",
       "75%    5.293306e+08  7.511600e+04  9.000000e+00   \n",
       "max    9.999905e+08  9.889500e+04  5.450000e+06   \n",
       "\n",
       "       Fiscal_year_duration_in_months          Year  \n",
       "count                       1495948.0  1.495948e+06  \n",
       "mean                             12.0  2.014475e+03  \n",
       "std                               0.0  1.246598e+00  \n",
       "min                              12.0  2.013000e+03  \n",
       "25%                              12.0  2.013000e+03  \n",
       "50%                              12.0  2.014000e+03  \n",
       "75%                              12.0  2.015000e+03  \n",
       "max                              12.0  2.018000e+03  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2000d9d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logRev = np.log10(np.clip(y_array, a_min=1, a_max=None))\n",
    "seaborn.kdeplot(logRev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Award notices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use another dataset which can be usefull to predict the Revenue of a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CallID</th>\n",
       "      <th>Publication_date</th>\n",
       "      <th>End_of_call_date</th>\n",
       "      <th>Departments_of_publication</th>\n",
       "      <th>Departments_of_provision</th>\n",
       "      <th>Call_summary</th>\n",
       "      <th>Call_title</th>\n",
       "      <th>Complete_call_description</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>CPV_classes</th>\n",
       "      <th>...</th>\n",
       "      <th>ID</th>\n",
       "      <th>awarded</th>\n",
       "      <th>description</th>\n",
       "      <th>incumbent_name</th>\n",
       "      <th>incumbent_address</th>\n",
       "      <th>incumbent_zipcode</th>\n",
       "      <th>incumbent_city</th>\n",
       "      <th>incumbent_country</th>\n",
       "      <th>number_of_received_bids</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16-119770</td>\n",
       "      <td>2016-08-11 00:00:00</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mission de maitrise d'oeuvre relative aux trav...</td>\n",
       "      <td>MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...</td>\n",
       "      <td>MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI PROJECT</td>\n",
       "      <td>11, avenue de la Capelette</td>\n",
       "      <td>13010</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>FR</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15-46335</td>\n",
       "      <td>2015-03-27 00:00:00</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>fourniture de r√©actifs immunos√©rologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fourniture de r√©actifs immunos√©rologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33696200 33696500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Kit pour recherche d'anticorps anti-IBR sur s√©...</td>\n",
       "      <td>ID-VET</td>\n",
       "      <td>310 rue Louis Pasteur</td>\n",
       "      <td>34790</td>\n",
       "      <td>Grabels</td>\n",
       "      <td>FR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15-46335</td>\n",
       "      <td>2015-03-27 00:00:00</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>fourniture de r√©actifs immunos√©rologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fourniture de r√©actifs immunos√©rologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33696200 33696500</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Kit pour recherche d'anticorps anti-IBR sur m√©...</td>\n",
       "      <td>IDEXX MONTPELLIER SAS</td>\n",
       "      <td>323 RUE DE LA GALERA</td>\n",
       "      <td>34090</td>\n",
       "      <td>MONTPELLIER</td>\n",
       "      <td>FR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CallID     Publication_date End_of_call_date Departments_of_publication  \\\n",
       "0  16-119770  2016-08-11 00:00:00       2016-09-20                         13   \n",
       "1   15-46335  2015-03-27 00:00:00       2015-04-25                         85   \n",
       "2   15-46335  2015-03-27 00:00:00       2015-04-25                         85   \n",
       "\n",
       "  Departments_of_provision                                       Call_summary  \\\n",
       "0                      NaN  mission de maitrise d'oeuvre relative aux trav...   \n",
       "1                       85  fourniture de r√©actifs immunos√©rologiques pour...   \n",
       "2                       85  fourniture de r√©actifs immunos√©rologiques pour...   \n",
       "\n",
       "                                          Call_title  \\\n",
       "0  MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                           Complete_call_description  Total_amount  \\\n",
       "0  MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...           NaN   \n",
       "1  Fourniture de r√©actifs immunos√©rologiques pour...           NaN   \n",
       "2  Fourniture de r√©actifs immunos√©rologiques pour...           NaN   \n",
       "\n",
       "         CPV_classes  ...   ID awarded  \\\n",
       "0           71000000  ...  NaN     Yes   \n",
       "1  33696200 33696500  ...    1     Yes   \n",
       "2  33696200 33696500  ...    2     Yes   \n",
       "\n",
       "                                         description         incumbent_name  \\\n",
       "0                                                NaN             AI PROJECT   \n",
       "1  Kit pour recherche d'anticorps anti-IBR sur s√©...                 ID-VET   \n",
       "2  Kit pour recherche d'anticorps anti-IBR sur m√©...  IDEXX MONTPELLIER SAS   \n",
       "\n",
       "            incumbent_address incumbent_zipcode incumbent_city  \\\n",
       "0  11, avenue de la Capelette             13010      Marseille   \n",
       "1       310 rue Louis Pasteur             34790        Grabels   \n",
       "2        323 RUE DE LA GALERA             34090    MONTPELLIER   \n",
       "\n",
       "   incumbent_country number_of_received_bids   amount  \n",
       "0                 FR                    13.0  83200.0  \n",
       "1                 FR                     2.0      NaN  \n",
       "2                 FR                     2.0      NaN  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award = pd.read_csv('data/award_notices_RAMP.csv.zip', low_memory=False,\n",
    "                    compression='zip')\n",
    "award.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304098, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallID                         object\n",
       "Publication_date               object\n",
       "End_of_call_date               object\n",
       "Departments_of_publication     object\n",
       "Departments_of_provision       object\n",
       "Call_summary                   object\n",
       "Call_title                     object\n",
       "Complete_call_description      object\n",
       "Total_amount                  float64\n",
       "CPV_classes                    object\n",
       "Buyer_name                     object\n",
       "Buyer_address                  object\n",
       "Buyer_zipcode                  object\n",
       "Buyer_city                     object\n",
       "Buyer_email                    object\n",
       "Buyer_URL                      object\n",
       "Contract_awarded               object\n",
       "Lot                             int64\n",
       "ID                             object\n",
       "awarded                        object\n",
       "description                    object\n",
       "incumbent_name                 object\n",
       "incumbent_address              object\n",
       "incumbent_zipcode              object\n",
       "incumbent_city                 object\n",
       "incumbent_country              object\n",
       "number_of_received_bids       float64\n",
       "amount                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Lot</th>\n",
       "      <th>number_of_received_bids</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.121260e+05</td>\n",
       "      <td>304098.000000</td>\n",
       "      <td>220936.000000</td>\n",
       "      <td>2.159540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5.177948e+08</td>\n",
       "      <td>2.073213</td>\n",
       "      <td>4.606900</td>\n",
       "      <td>1.145206e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>6.712391e+10</td>\n",
       "      <td>1.293831</td>\n",
       "      <td>7.982825</td>\n",
       "      <td>2.288319e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>9.900000e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.967891e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.240000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.821163e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.159775e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.568197e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.674995e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>1.000000e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_amount            Lot  number_of_received_bids        amount\n",
       "count  1.121260e+05  304098.000000            220936.000000  2.159540e+05\n",
       "mean   5.177948e+08       2.073213                 4.606900  1.145206e+08\n",
       "std    6.712391e+10       1.293831                 7.982825  2.288319e+10\n",
       "min    9.900000e-05       1.000000                 0.000000  0.000000e+00\n",
       "25%    1.967891e+05       1.000000                 2.000000  3.240000e+04\n",
       "50%    4.821163e+05       2.000000                 3.000000  1.159775e+05\n",
       "75%    1.568197e+06       3.000000                 5.000000  3.674995e+05\n",
       "max    1.000000e+13       5.000000               727.000000  1.000000e+13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallID                        0.000016\n",
       "Publication_date              0.000016\n",
       "End_of_call_date              0.000510\n",
       "Departments_of_publication    0.000016\n",
       "Departments_of_provision      0.674611\n",
       "Call_summary                  0.000016\n",
       "Call_title                    0.346484\n",
       "Complete_call_description     0.005426\n",
       "Total_amount                  0.631283\n",
       "CPV_classes                   0.082602\n",
       "Buyer_name                    0.000016\n",
       "Buyer_address                 0.017484\n",
       "Buyer_zipcode                 0.024084\n",
       "Buyer_city                    0.000016\n",
       "Buyer_email                   0.163766\n",
       "Buyer_URL                     0.211047\n",
       "Contract_awarded              0.000016\n",
       "Lot                           0.000000\n",
       "ID                            0.271015\n",
       "awarded                       0.034907\n",
       "description                   0.512683\n",
       "incumbent_name                0.034943\n",
       "incumbent_address             0.140126\n",
       "incumbent_zipcode             0.103414\n",
       "incumbent_city                0.061280\n",
       "incumbent_country             0.034943\n",
       "number_of_received_bids       0.273471\n",
       "amount                        0.289854\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NA values\n",
    "award.isna().sum() / award.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company revenue only\n",
    "\n",
    "First, let's predict using only the `comp` dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a transformer that deals with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                                   int64\n",
       "Name                                      object\n",
       "Activity_code (APE)                       object\n",
       "Address                                   object\n",
       "Zipcode                                  float64\n",
       "City                                      object\n",
       "Headcount                                float64\n",
       "Fiscal_year_end_date              datetime64[ns]\n",
       "Fiscal_year_duration_in_months           float64\n",
       "Year                                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical columns\n",
    "num_cols = ['Legal_ID', 'Headcount', 'Fiscal_year_duration_in_months', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have add a NameTransformer class to obtain the top 1000 words used in the Name entity and keep only 2 of them by Name. This method able me to regroup entities which can have 'bakery' in their name for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameTransformer(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.best_words_ = {}\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        temp_val = recordlinkage.preprocessing.clean(X.Name)\n",
    "        temp_val = temp_val.apply(lambda x:[str(x).split(\" \")]).reset_index()\n",
    "        temp_val.columns = [\"Index_temp\", \"Name\"]\n",
    "        temp_val[\"CA\"] = y\n",
    "        df1 = pd.DataFrame({ \"Index_temp\": np.repeat(temp_val.Index_temp.values, \n",
    "                    [len(x) for x in (chain.from_iterable(temp_val.Name))]),\n",
    "                    \"CA\": np.repeat(temp_val.CA.values, \n",
    "                    [len(x) for x in (chain.from_iterable(temp_val.Name))]),\n",
    "           \n",
    "                    \"Name\": list(chain.from_iterable(chain.from_iterable(temp_val.Name)))})\n",
    "        CA_mean = y.mean()\n",
    "        df1[\"CA\"] = df1[\"CA\"] - CA_mean\n",
    "        self.best_words_ = df1[[\"Name\",\"CA\"]].groupby(\"Name\").agg(\"mean\")[\"CA\"].to_dict()\n",
    " \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        temp_val = recordlinkage.preprocessing.clean(X.Name)\n",
    " \n",
    "        temp_val = temp_val.apply(lambda x:[str(x).split(\" \")]).reset_index()\n",
    " \n",
    "        temp_val.columns = [\"Index_temp\", \"Name\"]\n",
    "        df1 = pd.DataFrame({ \"Index_temp\": np.repeat(temp_val.Index_temp.values, \n",
    "                                    [len(x) for x in (chain.from_iterable(temp_val.Name))]),\n",
    "                     \"Name\": list(chain.from_iterable(chain.from_iterable(temp_val.Name)))})\n",
    "        df1[\"cat_names\"] = df1.Name.map(self.best_words_).fillna(0)\n",
    "        return(df1[[\"Index_temp\",\"cat_names\"]].groupby(\"Index_temp\").agg(\"sum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I made a target encoder on APE, City on mean and std and median\n",
    "\n",
    "\n",
    "df = pd.concat([X_df,pd.Series(y_array)], axis=1)\n",
    "Rev_col = df.columns[-1]\n",
    "avg = df.groupby(['Activity_code (APE)'])[Rev_col].agg(['mean', 'std'])\n",
    "avg = pd.DataFrame( avg)\n",
    "avg = avg.rename(columns={\"mean\":\"APE_avg\", \"std\":\"APE_std\"})\n",
    "revenue_avg_std = avg\n",
    "\n",
    "avg = df.groupby(['City'])[Rev_col].agg(['mean', 'std'])\n",
    "avg = pd.DataFrame( avg)\n",
    "avg = avg.rename(columns={\"mean\":\"APE_city_avg\", \"std\":\"APE_city_std\"})\n",
    "rev_city_avg_std = avg\n",
    "\n",
    "ape = X_df[[\"Activity_code (APE)\"]].dropna()\n",
    "ape = pd.concat((ape, pd.Series(y_array)), axis=1)\n",
    "ape = ape.rename(columns={0:\"Y\"})\n",
    "ape = ape.groupby(\"Activity_code (APE)\").agg([\"median\"])\n",
    "ape[\"APE_rank\"] = ape[\"Y\"][\"median\"].rank(ascending=False)\n",
    "ape[\"APE\"] = ape.index\n",
    "ape_rank = pd.DataFrame({\"APE\":ape[\"APE\"], \"APE_rank\":ape[\"APE_rank\"]})\n",
    "\n",
    "\n",
    "city = X_df[[\"City\"]].dropna()\n",
    "city = pd.concat((city, pd.Series(y_array)), axis=1)\n",
    "city = city.rename(columns={0:\"Y\"})\n",
    "city = city.groupby(\"City\").agg([\"median\"])\n",
    "city[\"city_rank\"] = city[\"Y\"][\"median\"].rank(ascending=False)\n",
    "city[\"city\"] = city.index\n",
    "city_rank = pd.DataFrame({\"city\":city[\"city\"], \"city_rank\":city[\"city_rank\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have add some features to help the regressor to predict the good revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipcodes(X): ##Transformation of ZipCodes : transform to numerical values\n",
    "    zipcode_nums = pd.to_numeric(X['Zipcode'], errors='coerce')\n",
    "    return zipcode_nums.values[:, np.newaxis]\n",
    "zipcode_transformer = FunctionTransformer(zipcodes, validate=False)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median'))])\n",
    "\n",
    "def process_date(X): ##Transformation of date : in format : Year-Month-Day\n",
    "    date = pd.to_datetime(X['Fiscal_year_end_date'], format='%Y-%m-%d')\n",
    "    return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "date_transformer = FunctionTransformer(process_date, validate=False)\n",
    "\n",
    "def process_APE(X): ## Transformation of APE : use the new column with target encoder\n",
    "    APE = pd.merge(X, ape_rank, left_on=\"Activity_code (APE)\", right_on=\"APE\", how=\"left\")\n",
    "    return APE[[\"APE_rank\"]]\n",
    "APE_transformer = FunctionTransformer(process_APE, validate=False)\n",
    "\n",
    "def process_city(X): ## Transformation of City : use the new column with target encoder\n",
    "    city = pd.merge(X, city_rank, left_on=\"City\", right_on=\"city\", how=\"left\")\n",
    "    return city[[\"city_rank\"]]\n",
    "City_transformer = FunctionTransformer(process_city, validate=False)\n",
    "\n",
    "def merge_city_avg(X): #add column with the target encoder\n",
    "        df = pd.merge(X, rev_city_avg_std, left_on='City', right_on='City', how='left')\n",
    "        return df[[\"APE_city_avg\", \"APE_city_std\"]]\n",
    "merge_transformer_city_avg = FunctionTransformer(merge_city_avg, validate=False)\n",
    "\n",
    "def merge_avg(X): #add column with the target encoder\n",
    "        df = pd.merge(X,revenue_avg_std, left_on='Activity_code (APE)', right_on='Activity_code (APE)', how='left')\n",
    "        return df[[\"APE_avg\", \"APE_std\"]]\n",
    "merge_transformer_avg = FunctionTransformer(merge_avg, validate=False)\n",
    "\n",
    "def headcount_process(X): # put the mean to nan values (63%)\n",
    "    dico = X[[\"Legal_ID\", \"Headcount\"]].groupby(\"Legal_ID\").agg(np.nanmean)[\"Headcount\"].to_dict()\n",
    "    return(X[\"Legal_ID\"].map(dico).values.reshape(-1,1))\n",
    "headcount_transformer = FunctionTransformer(headcount_process, validate=False)\n",
    "\n",
    "def departements(X): # add departements columns : keep only the 2 first number of zip code\n",
    "    dept = pd.to_numeric(X['Zipcode'].astype(str).str[:2], errors='coerce')\n",
    "    return dept[:, np.newaxis]\n",
    "dept_transformer = FunctionTransformer(departements, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can test our model, we need to define our unique scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    true = np.maximum(5., np.log10(np.maximum(1., y_true)))\n",
    "    pred = np.maximum(5., np.log10(np.maximum(1., y_pred)))\n",
    "    \n",
    "    loss = np.mean(np.abs(true - pred))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "fan_loss = make_scorer(loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "Now let us predict using a naive merge of `award` and `comp` datasets.\n",
    "\n",
    "The naive merge will only use the name of the company. To aid the merging we will convert the name to all lower case and remove punctuation and white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "award['i_Name_processed'] = award['incumbent_name'].str.lower()\n",
    "award['i_Name_processed'] = award['i_Name_processed'].str.replace('[^\\w]','')\n",
    "\n",
    "#Add columns for the merge of the 2 datasets\n",
    "award_i_features = award.groupby(['i_Name_processed'])['amount'].agg(['count','sum'])\n",
    "award_i_features[[\"i_amount\", \"i_count\"]] = award_i_features[[\"sum\", 'count']]\n",
    "\n",
    "award['b_Name_processed'] = award['Buyer_name'].str.lower()\n",
    "award['b_Name_processed'] = award['b_Name_processed'].str.replace('[^\\w]','')\n",
    "award_b_features = award.groupby(['b_Name_processed'])['amount'].agg(['count','sum'])\n",
    "award_b_features[[\"b_amount\", \"b_count\"]] = award_b_features[[\"sum\", 'count']]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will perform a naive merge of `X_df` and `award_features`. \n",
    "\n",
    "Be careful in this step to ensure that the **order** of `X_df` is not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_naive(X):\n",
    "\n",
    "    X['NameClean'] = X['Name'].str.lower()\n",
    "    X['NameClean'] = X['NameClean'].str.replace('[^\\w]','')\n",
    "\n",
    "    X = pd.merge(X, award_i_features[[\"i_amount\", 'i_count']], left_on='NameClean', right_index=True, how='left')\n",
    "    X = pd.merge(X, award_b_features[[\"b_amount\", 'b_count']], left_on='NameClean', right_index=True, how='left')\n",
    "\n",
    "    X[\"amount\"] = X[[\"b_amount\", \"i_amount\"]].sum(axis=1).replace(0, np.nan)\n",
    "    X[\"count\"] = X[[\"b_count\", \"i_count\"]].sum(axis=1).replace(0, np.nan)\n",
    "    return X[['count','amount']]\n",
    "merge_transformer = FunctionTransformer(merge_naive, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ape_target_encoder = TargetEncoder()\n",
    "zipcode_target_encoder = TargetEncoder()\n",
    "\n",
    "nt = NameTransformer()\n",
    "te = TargetEncoder()\n",
    "\n",
    "num_cols = ['Legal_ID', 'Headcount', 'Year']\n",
    "zipcode_col = ['Zipcode']\n",
    "date_cols = ['Fiscal_year_end_date']\n",
    "APE_col = ['Activity_code (APE)']\n",
    "merge_col = ['Name']\n",
    "drop_cols = ['Address', 'City', 'Fiscal_year_duration_in_months']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('zipcode', make_pipeline(zipcode_transformer, SimpleImputer(strategy='median'), zipcode_target_encoder, StandardScaler()), zipcode_col),\n",
    "        ('num', make_pipeline(numeric_transformer, StandardScaler()), num_cols),\n",
    "        ('headcount', make_pipeline(headcount_transformer, SimpleImputer(strategy='constant',fill_value=0), StandardScaler()), [\"Headcount\", \"Legal_ID\"]), \n",
    "        ('date', make_pipeline(date_transformer, SimpleImputer(strategy='median'), StandardScaler()), date_cols),\n",
    "        ('revenue_avg_std', make_pipeline(merge_transformer_avg, SimpleImputer(strategy='median')), ['Activity_code (APE)']),\n",
    "        ('revenue_city_avg_std', make_pipeline(merge_transformer_city_avg, SimpleImputer(strategy='median')), ['City']),\n",
    "        ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median'), ape_target_encoder, StandardScaler()), APE_col),\n",
    "        ('city', make_pipeline(City_transformer, SimpleImputer(strategy='median')), [\"City\"]),\n",
    "        ('merge', make_pipeline(merge_transformer, SimpleImputer(strategy='median'), StandardScaler()), merge_col),\n",
    "        ('name_col', make_pipeline(nt, te), merge_col),\n",
    "        (\"departement\",make_pipeline(dept_transformer, SimpleImputer(strategy='median')), zipcode_col),\n",
    "        ('drop cols', 'drop', drop_cols),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our model. Note that we use `GroupShuffleSplit` using `Legal_ID` as the group so that the same company ('Legal_ID') only appears in either 'train' or 'test' but does not appear both in 'train' **and** 'test'.\n",
    "\n",
    "This reflects the same conditions of this challenge where, the private 'test' data (on RAMP) does not contain any company that also appears in the public 'train' dataset you have access to. This is because `Revenue` for the same company is often very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have these parameters, i have done a Grid-Search and used the learning-curve of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quentinpuyrazat/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## To use the great loss with the lgb, i have done some modifications (the loss used is not MSE)\n",
    "## but this one defined before\n",
    "import lightgbm as lgb\n",
    "regressor = lgb.LGBMRegressor(bagging_fraction =0.46425315978835247,\n",
    "                      learning_rate = 0.1004089596870895,\n",
    "                      max_bin = 248,\n",
    "                      max_depth = 13,\n",
    "                      min_data_in_leaf = 16,\n",
    "                      num_leaves = 207,\n",
    "                      objective = 'mae',\n",
    "                      reg_lambda = 0.8560898755683229,\n",
    "                      n_jobs = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our model within this notebook, using `preprocessor_merge` and `regressor` defined above, in a `Pipeline()`. \n",
    "\n",
    "Once you are happy with a solution, you can transfer your solution to `feature_extractor.py` and `regressor.py` files and test your submission using RAMP (see 'Submissions')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 3.657505e-01 (+/- 8.015486e-03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', regressor)])\n",
    "\n",
    "cv = GroupShuffleSplit(n_splits=5, test_size=0.25)\n",
    "\n",
    "step = 30  # to limit the running time we divide sample size by step\n",
    "scores_merge = -cross_val_score(clf, X_df[::step], y_array[::step], cv=cv,\n",
    "                                scoring=fan_loss,\n",
    "                                groups=X_df['Legal_ID'][::step],\n",
    "                                n_jobs=2)\n",
    "\n",
    "print(\"mean: %e (+/- %e)\" % (scores_merge.mean(), scores_merge.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code able me to be 14th out of 127 in equality with the 5th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid-Search with learning-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ngridParams = {\\n    \\'n_estimators\\' : list(range(1,400)),\\n    \\'learning_rate\\': [0.05],\\n    \\'num_leaves\\': list(range(1,400)),\\n    \\'max_depth\\' : list(range(1,400)),\\n    \\'max_bin\\' : list(range(1,400)),\\n    \\'subsample\\' : np.linspace(0.1,1,10),\\n    \\'bagging_fraction\\' :np.linspace(0.1,1,10),\\n    \\'objective\\':[\\'mae\\']\\n    }\\n\\nclf = lgb.LGBMRegressor()\\ngrid = RandomizedSearchCV(clf,gridParams,verbose=1,cv=10,n_jobs = 1,n_iter=10)\\n#grid.fit(X_df,y_array)\\n\\n\\n\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import learning_curve\\n\\n\\ndef plot_learning_curve(estimator, X, y, ylim=(0, 1.1), cv=5,\\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5),\\n                        scoring=None):\\n    plt.title(\"Learning curves for %s\" % type(estimator).__name__)\\n    plt.grid()\\n    plt.xlabel(\"Training examples\")\\n    plt.ylabel(\"Score\")\\n    train_sizes, train_scores, validation_scores = learning_curve(\\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\\n        scoring=scoring)\\n    train_scores_mean = np.mean(train_scores, axis=1)\\n    validation_scores_mean = np.mean(validation_scores, axis=1)\\n\\n    plt.plot(train_sizes, train_scores_mean, \\'o-\\', color=\"r\",\\n             label=\"Training score\")\\n    plt.plot(train_sizes, validation_scores_mean, \\'o-\\', color=\"g\",\\n             label=\"Cross-validation score\")\\n    plt.legend(loc=\"best\")\\n    print(\"Best validation score: {:.4f}\".format(validation_scores_mean[-1]))'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "gridParams = {\n",
    "    'n_estimators' : list(range(1,400)),\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': list(range(1,400)),\n",
    "    'max_depth' : list(range(1,400)),\n",
    "    'max_bin' : list(range(1,400)),\n",
    "    'subsample' : np.linspace(0.1,1,10),\n",
    "    'bagging_fraction' :np.linspace(0.1,1,10),\n",
    "    'objective':['mae']\n",
    "    }\n",
    "\n",
    "clf = lgb.LGBMRegressor()\n",
    "grid = RandomizedSearchCV(clf,gridParams,verbose=1,cv=10,n_jobs = 1,n_iter=10)\n",
    "#grid.fit(X_df,y_array)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, ylim=(0, 1.1), cv=5,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                        scoring=None):\n",
    "    plt.title(\"Learning curves for %s\" % type(estimator).__name__)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n",
    "        scoring=scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    print(\"Best validation score: {:.4f}\".format(validation_scores_mean[-1]))\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
